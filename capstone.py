# -*- coding: utf-8 -*-
"""capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JT4B1F8i4tbeU2n-HF_GTKaqKako7Bhm
"""

import streamlit as st
import pandas as pd
import pickle

# Load the dataset
df = pd.read_csv('car_details.csv')

# Explore the dataset
st.write(df.head())
st.write(df.info())

# Handle missing values
st.write(df.isnull().sum())
df = df.dropna()

# Encode categorical variables
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['fuel'] = le.fit_transform(df['fuel'])
df['seller_type'] = le.fit_transform(df['seller_type'])
df['transmission'] = le.fit_transform(df['transmission'])
df['owner'] = le.fit_transform(df['owner'])

# Exploratory Data Analysis
# Visualize the distribution of numerical features
st.write("Distribution of Car Year")

# Use Matplotlib to create the histogram
fig, ax = plt.subplots()
ax.hist(df['year'])
st.pyplot(fig) # Display the Matplotlib figure in Streamlit

st.write("Distribution of Selling Price")
fig, ax = plt.subplots()
ax.hist(df['selling_price'])
st.pyplot(fig)

st.write("Distribution of Kilometers Driven")
fig, ax = plt.subplots()
ax.hist(df['km_driven'])
st.pyplot(fig)

# Analyze the relationships between features
st.write("Correlation Matrix")

# Calculate correlation on numerical columns only
numerical_df = df.select_dtypes(include=['number'])
st.write(numerical_df.corr())

# Prepare the data for machine learning
X = df.drop(['name','selling_price'], axis=1) # Remove the 'name' column from features
y = df['selling_price'] # Predict the 'selling_price' instead of 'name'

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train and evaluate machine learning models
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

lr = LinearRegression()
lr.fit(X_train, y_train) # Now this should work as y_train is numerical
lr_pred = lr.predict(X_test)
lr_mse = mean_squared_error(y_test, lr_pred)
lr_r2 = r2_score(y_test, lr_pred)

rf = RandomForestRegressor()
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_mse = mean_squared_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)

# Determine the best model based on the evaluation metrics

# Save the best model
import pickle
pickle.dump(best_model, open('car_details_model.pkl', 'wb'))

# Load the saved model
loaded_model = pickle.load(open('car_details_model.pkl', 'rb'))

